{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3452e36c",
      "metadata": {},
      "source": [
        "# Spark SQL Assignment: Relational Queries\n",
        "\n",
        "This notebook contains **questions only** (no solutions). Solve each using **Spark SQL** (i.e., `spark.sql(...)`).\n",
        "\n",
        "## Files Required\n",
        "Ensure the following CSV files are available (or update paths in the load cell):\n",
        "- sy_account_20251225_155056.csv\n",
        "- ab_user_20251225_155056.csv\n",
        "- sy_app_module_20251225_155056.csv\n",
        "- sy_application_20251225_155056.csv\n",
        "- in_model_20251225_155056.csv\n",
        "- in_workspace_20251225_155056.csv\n",
        "- in_timeseries_version_20251225_155057.csv\n",
        "- in_material_20251225_155057.csv\n",
        "- in_resource_20251225_155057.csv\n",
        "- in_time_dimension_20251225_155057.csv\n",
        "- in_timeseries_20251225_155057.csv\n",
        "- in_timeseries_data_20251225_155101.csv\n",
        "\n",
        "> **Note:** The load cell registers **temporary views** with the same names so you can query them via `SELECT ... FROM view_name`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3a881063",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Spark for Spark SQL\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "spark = SparkSession.builder.appName('spark_sql_assignment').getOrCreate()\n",
        "spark.conf.set('spark.sql.shuffle.partitions', '8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ac1e7fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CSVs and create temp views for Spark SQL\n",
        "\n",
        "ab_user_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\ab_user_20251225_155056.csv\",header=True)\n",
        "ab_user_df.createOrReplaceTempView(\"ab_user\")\n",
        "\n",
        "in_material_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_material_20251225_155057.csv\",header=True)\n",
        "in_material_df.createOrReplaceTempView(\"in_material\")\n",
        "\n",
        "in_model_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_model_20251225_155056.csv\",header=True)\n",
        "in_model_df.createOrReplaceTempView(\"in_model\")\n",
        "\n",
        "in_resource_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_resource_20251225_155057.csv\",header=True)\n",
        "in_resource_df.createOrReplaceTempView(\"in_resource\")\n",
        "\n",
        "in_time_dimension_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_time_dimension_20251225_155057.csv\",header=True)\n",
        "in_time_dimension_df.createOrReplaceTempView(\"in_time_dimension\")\n",
        "\n",
        "in_timeseries_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_timeseries_20251225_155057.csv\",header=True)\n",
        "in_timeseries_df.createOrReplaceTempView(\"in_timeseries\")\n",
        "\n",
        "in_timeseries_data_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_timeseries_data_20251225_155101.csv\",header=True)\n",
        "in_timeseries_data_df.createOrReplaceTempView(\"in_timeseries_data\")\n",
        "\n",
        "in_timeseries_version_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_timeseries_version_20251225_155057.csv\",header=True)\n",
        "in_timeseries_version_df.createOrReplaceTempView(\"in_timeseries_version\")\n",
        "\n",
        "in_workspace_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\in_workspace_20251225_155056.csv\",header=True)\n",
        "in_workspace_df.createOrReplaceTempView(\"in_workspace\")\n",
        "\n",
        "sy_account_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\sy_account_20251225_155056.csv\",header=True)\n",
        "sy_account_df.createOrReplaceTempView(\"sy_account\")\n",
        "\n",
        "sy_app_module_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\sy_app_module_20251225_155056.csv\",header=True)\n",
        "sy_app_module_df.createOrReplaceTempView(\"sy_app_module\")\n",
        "\n",
        "sy_application_df= spark.read.csv(r\"C:\\Users\\omkar\\Desktop\\python_practice\\zip_assinment_o\\sy_application_20251225_155056.csv\",header=True)\n",
        "sy_application_df.createOrReplaceTempView(\"sy_application\")\n",
        "\n",
        "\n",
        "# Optional: parse datetime column for downstream tasks if needed\n",
        "# in_timeseries_data = in_timeseries_data.withColumn('dttime', F.to_timestamp('dttime'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bef2ec",
      "metadata": {},
      "source": [
        "**Q1.** Retrieve all columns from the `sy_account` table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8696e065",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------------------+\n",
            "| id|               name|\n",
            "+---+-------------------+\n",
            "|  2|              Linde|\n",
            "|  3|              Enpro|\n",
            "|  4|         Indian Oil|\n",
            "|  5|Standard Automotive|\n",
            "|  1|       ESPL_Account|\n",
            "|  7|           ESPL_UAT|\n",
            "+---+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "          \n",
        "SELECT * FROM sy_account\n",
        "\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b00778",
      "metadata": {},
      "source": [
        "**Q2.** Find all users from the `ab_user` table where `account_id = 3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "37dca1ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+--------+----------+\n",
            "| id|username|account_id|\n",
            "+---+--------+----------+\n",
            "|  7|pratik.m|         3|\n",
            "+---+--------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "          select * from ab_user\n",
        "          where account_id=3\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2ac30f4",
      "metadata": {},
      "source": [
        "**Q3.** Display all application modules from `sy_app_module` ordered by `app_name` in ascending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8b1b7064",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------+--------+--------------------+\n",
            "|app_id|application_id|app_code|            app_name|\n",
            "+------+--------------+--------+--------------------+\n",
            "|    14|             3|    xsfc|Radar-Demand Plan...|\n",
            "|     6|             2|    xpnp|        Trinity-S&OP|\n",
            "|    19|             5|    xbds| XBridge-Integration|\n",
            "+------+--------------+--------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "          select * from sy_app_module\n",
        "          order by app_name\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c494bca",
      "metadata": {},
      "source": [
        "**Q4.** Fetch the first 10 records from the `in_timeseries_data` table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e66835b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+----------+\n",
            "|ts_data_id|ts_id|             dttime|     data|version_id|\n",
            "+----------+-----+-------------------+---------+----------+\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|       130|\n",
            "|  44471774|27902|2018-12-01 00:00:00| 11513.37|       130|\n",
            "|  44471775|27902|2019-01-01 00:00:00|11556.125|       130|\n",
            "|  44471776|27902|2019-02-01 00:00:00|11598.547|       130|\n",
            "|  44471777|27902|2019-03-01 00:00:00|11643.222|       130|\n",
            "|  44471778|27902|2019-04-01 00:00:00| 11687.96|       130|\n",
            "|  44471779|27902|2019-05-01 00:00:00|11732.147|       130|\n",
            "|  44471780|27902|2019-06-01 00:00:00|11775.567|       130|\n",
            "|  44471781|27902|2019-07-01 00:00:00|11820.099|       130|\n",
            "|  44471782|27902|2019-08-01 00:00:00|11863.516|       130|\n",
            "+----------+-----+-------------------+---------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "          select * from in_timeseries_data\n",
        "          limit 10\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22154d1a",
      "metadata": {},
      "source": [
        "**Q5.** Count the total number of materials in the `in_material` table for `workspace_id = 53`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c809e598",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------+\n",
            "|workspace_id|material_count|\n",
            "+------------+--------------+\n",
            "|          53|            19|\n",
            "+------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "       select workspace_id,count(*) AS material_count\n",
        "from in_material\n",
        "where workspace_id = 53\n",
        "group by workspace_id;\n",
        "\"\"\").show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d544740",
      "metadata": {},
      "source": [
        "**Q6.** Display all users from `ab_user` ordered by `username` in ascending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "82f858ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----------+----------+\n",
            "| id|   username|account_id|\n",
            "+---+-----------+----------+\n",
            "|  1|      admin|         1|\n",
            "|  5| customer_1|         1|\n",
            "|  3|hetal.patel|         1|\n",
            "|  7|   pratik.m|         3|\n",
            "|  4|       ravi|         1|\n",
            "+---+-----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "          select * from ab_user \n",
        "          order by username \n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8852b57d",
      "metadata": {},
      "source": [
        "**Q7.** Find all timeseries from `in_timeseries` where `workspace_id = 53` and `material_id = 83498`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "14532309",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------+------------+-------------+\n",
            "|ts_id|material_id|geography_id|time_level_id|\n",
            "+-----+-----------+------------+-------------+\n",
            "|27803|      83498|       30201|            5|\n",
            "|27808|      83498|       30202|            5|\n",
            "|27813|      83498|       30203|            5|\n",
            "|27818|      83498|       30204|            5|\n",
            "|27823|      83498|       30205|            5|\n",
            "|27828|      83498|       30206|            5|\n",
            "|27363|      83498|       30113|            5|\n",
            "|27368|      83498|       30114|            5|\n",
            "|27373|      83498|       30115|            5|\n",
            "|27378|      83498|       30116|            5|\n",
            "|27383|      83498|       30117|            5|\n",
            "|27388|      83498|       30118|            5|\n",
            "|27393|      83498|       30119|            5|\n",
            "|27398|      83498|       30120|            5|\n",
            "|27403|      83498|       30121|            5|\n",
            "|27408|      83498|       30122|            5|\n",
            "|27413|      83498|       30123|            5|\n",
            "|27418|      83498|       30124|            5|\n",
            "|27423|      83498|       30125|            5|\n",
            "|27428|      83498|       30126|            5|\n",
            "+-----+-----------+------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "          select * from in_timeseries\n",
        "          where material_id=83498\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6930f3",
      "metadata": {},
      "source": [
        "**Q8.** Retrieve all versions from `in_timeseries_version` where `version_id` is 125, 126, or 130."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0b04c6f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------------+-----------+--------------------+\n",
            "|version_id|      version_name|modified_by|       modified_time|\n",
            "+----------+------------------+-----------+--------------------+\n",
            "|       125|               Raw|          1|2022-05-05 13:11:...|\n",
            "|       126|Manually Corrected|          1|2022-05-05 13:11:...|\n",
            "|       130|       Forecast-MA|          1|2022-05-11 09:49:...|\n",
            "+----------+------------------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select * from in_timeseries_version\n",
        "          where version_id  in (125,126,130)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c68ee0",
      "metadata": {},
      "source": [
        "**Q9.** Retrieve the first 5 materials from `in_material` where `workspace_id = 53`, ordered by `material_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "61cb899b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+------------+\n",
            "|material_id|material_name|workspace_id|\n",
            "+-----------+-------------+------------+\n",
            "|      83516|          All|          53|\n",
            "|      83505|    Auto Lube|          53|\n",
            "|      83504|       Diesel|          53|\n",
            "|      83509|         Fuel|          53|\n",
            "|      83503|     Gasoline|          53|\n",
            "+-----------+-------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select * from in_material \n",
        "where workspace_id=53\n",
        "order by material_name asc\n",
        "limit 5\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86531980",
      "metadata": {},
      "source": [
        "**Q10.** Count the total number of users in the `ab_user` table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f3fcadc9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|total_users|\n",
            "+-----------+\n",
            "|          5|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select count(*) as total_users from ab_user \n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9cffb33",
      "metadata": {},
      "source": [
        "**Q11.** Calculate the sum of all `data` values from the `in_timeseries_data` table where `version_id = 125`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f29d5363",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------------------+\n",
            "|version_id|            sum_data|\n",
            "+----------+--------------------+\n",
            "|       125|1.1886324623341472E8|\n",
            "+----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select version_id,sum(data) as sum_data\n",
        "from in_timeseries_data\n",
        "where version_id = 125\n",
        "group by version_id\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c9d60ac",
      "metadata": {},
      "source": [
        "**Q12.** Find the average value of `data` from the `in_timeseries_data` table where `workspace_id = 53`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "68736a79",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|          avg_data|\n",
            "+------------------+\n",
            "|4571.6633166697975|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select avg(data) as avg_data from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7397bd5a",
      "metadata": {},
      "source": [
        "**Q13.** Find the maximum and minimum `data` values from the `in_timeseries_data` table where `version_id = 130`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d56b25b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------+\n",
            "|max_data|min_data|\n",
            "+--------+--------+\n",
            "|959.9358|     0.0|\n",
            "+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select max(data) as max_data,min(data) as min_data from in_timeseries_data\n",
        "where version_id=130\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45098e35",
      "metadata": {},
      "source": [
        "**Q14.** Count the number of timeseries records grouped by `material_id` from the `in_timeseries` table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3b5cc1aa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+\n",
            "|material_id|count_records|\n",
            "+-----------+-------------+\n",
            "|      83500|          100|\n",
            "|      83502|          100|\n",
            "|      83499|          100|\n",
            "|      83504|          100|\n",
            "|      83505|          100|\n",
            "|      83498|          100|\n",
            "|      83506|            1|\n",
            "|      83501|          100|\n",
            "|      83503|          100|\n",
            "|      83507|            1|\n",
            "|      83508|            1|\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select material_id,count(*) as count_records from in_timeseries\n",
        "group by material_id\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd556f5",
      "metadata": {},
      "source": [
        "**Q15.** Count the number of users grouped by `account_id` where `account_id` is not null."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7dc1618f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------+\n",
            "|account_id|no_of_users|\n",
            "+----------+-----------+\n",
            "|         1|          4|\n",
            "|         3|          1|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select account_id,count(*) as no_of_users from ab_user \n",
        "where account_id is not null\n",
        "group by account_id\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23046898",
      "metadata": {},
      "source": [
        "**Q16.** Display `version_id`, total record count, and average `data` value grouped by `version_id` from `in_timeseries_data` where `workspace_id = 53`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4629ba96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------------+------------------+\n",
            "|version_id|count_of_records|          avd_data|\n",
            "+----------+----------------+------------------+\n",
            "|       130|             234|17071.166381623927|\n",
            "+----------+----------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select version_id,count(*) as count_of_records , avg(data) as avd_data from in_timeseries_data\n",
        "where version_id=130\n",
        "group by version_id\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "426ed3c5",
      "metadata": {},
      "source": [
        "**Q17.** Find all `material_id` values that have more than 3 timeseries records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e4290669",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----+\n",
            "|material_id|count|\n",
            "+-----------+-----+\n",
            "|      83500|  100|\n",
            "|      83502|  100|\n",
            "|      83499|  100|\n",
            "|      83504|  100|\n",
            "|      83505|  100|\n",
            "|      83498|  100|\n",
            "|      83501|  100|\n",
            "|      83503|  100|\n",
            "+-----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select material_id,count(*) as count from in_timeseries \n",
        "group by material_id\n",
        "having count>1\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6464982e",
      "metadata": {},
      "source": [
        "**Q18.** Count the number of timeseries data records grouped by both `version_id` and `ts_id` where `workspace_id = 53`, and show only those with `count > 1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0a54c778",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+---------+\n",
            "|version_id|ts_id|count_rec|\n",
            "+----------+-----+---------+\n",
            "|       125|27373|       52|\n",
            "|       125|27375|       52|\n",
            "|       125|27389|       52|\n",
            "|       125|27392|       52|\n",
            "|       125|27419|       52|\n",
            "|       125|27430|       52|\n",
            "|       125|27436|       52|\n",
            "|       125|27438|       52|\n",
            "|       125|27458|       52|\n",
            "|       125|27470|       52|\n",
            "|       125|27474|       52|\n",
            "|       125|27487|       52|\n",
            "|       125|27489|       52|\n",
            "|       125|27490|       52|\n",
            "|       125|27491|       52|\n",
            "|       125|27498|       52|\n",
            "|       125|27507|       52|\n",
            "|       125|27519|       52|\n",
            "|       125|27532|       52|\n",
            "|       125|27534|       52|\n",
            "+----------+-----+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select version_id,ts_id,count(*) as count_rec from in_timeseries_data\n",
        "where version_id=125\n",
        "group by version_id,ts_id\n",
        "having count_rec >1\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d1c342",
      "metadata": {},
      "source": [
        "**Q19.** Display `username` along with account name. Output columns: `id`, `username`, `account_id`, `name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a0c27a0d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----------+----------+-------------------+\n",
            "| id|   username|account_id|               name|\n",
            "+---+-----------+----------+-------------------+\n",
            "|  1|      admin|         1|       ESPL_Account|\n",
            "|  3|hetal.patel|         1|              Enpro|\n",
            "|  4|       ravi|         1|         Indian Oil|\n",
            "|  5| customer_1|         1|Standard Automotive|\n",
            "|  7|   pratik.m|         3|           ESPL_UAT|\n",
            "+---+-----------+----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select id, username, account_id,name from ab_user\n",
        "join sy_account \n",
        "using (id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "190947d4",
      "metadata": {},
      "source": [
        "**Q20.** Show all application names and their corresponding application module details. Output columns: `app_id`, `app_code`, `app_name`, `application_id`, `application_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ff542c8b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+--------------------+--------------+----------------+\n",
            "|app_id|app_code|            app_name|application_id|application_name|\n",
            "+------+--------+--------------------+--------------+----------------+\n",
            "|    19|    xbds| XBridge-Integration|             5|         XBridge|\n",
            "|    14|    xsfc|Radar-Demand Plan...|             3|          XSight|\n",
            "|     6|    xpnp|        Trinity-S&OP|             2|           XPlan|\n",
            "+------+--------+--------------------+--------------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select app_id, app_code, app_name, application_id,application_name from sy_app_module\n",
        "join sy_application \n",
        "using (application_id) \n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7674fffc",
      "metadata": {},
      "source": [
        "**Q21.** Retrieve model names along with their associated application names. Output columns: `model_id`, `model_name`, `application_id`, `application_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "404485e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----------+--------------+----------------+\n",
            "|model_id| model_name|application_id|application_name|\n",
            "+--------+-----------+--------------+----------------+\n",
            "|      29|Oil and Gas|             3|          XSight|\n",
            "+--------+-----------+--------------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select model_id, model_name, application_id,application_name from in_model \n",
        "join sy_application\n",
        "using(application_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d9bf5b",
      "metadata": {},
      "source": [
        "**Q22.** Display workspace names with their corresponding model names. Output columns: `workspace_id`, `workspace_name`, `model_id`, `model_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "dce4d199",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------+--------+-----------+\n",
            "|workspace_id|workspace_name|model_id| model_name|\n",
            "+------------+--------------+--------+-----------+\n",
            "|          53|        Nayara|      29|Oil and Gas|\n",
            "+------------+--------------+--------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select  workspace_id, workspace_name, model_id,model_name from in_workspace\n",
        "join in_model\n",
        "using (model_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57920a3",
      "metadata": {},
      "source": [
        "**Q23.** Show all version names along with their workspace names where `workspace_id = 53`. Output columns: `version_id`, `version_name`, `workspace_id`, `workspace_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "288a3f07",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------------------+------------+--------------+\n",
            "|version_id|      version_name|workspace_id|workspace_name|\n",
            "+----------+------------------+------------+--------------+\n",
            "|       125|               Raw|          53|        Nayara|\n",
            "|       126|Manually Corrected|          53|        Nayara|\n",
            "|       130|       Forecast-MA|          53|        Nayara|\n",
            "|       135|  Forecast-Bestfit|          53|        Nayara|\n",
            "+----------+------------------+------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select v.version_id,v.version_name,w.workspace_id,w.workspace_name\n",
        "from in_workspace w\n",
        "cross join in_timeseries_version v\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d079a72",
      "metadata": {},
      "source": [
        "**Q24.** Display material names with their workspace names. Output columns: `material_id`, `material_name`, `workspace_id`, `workspace_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "89a19907",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+------------+--------------+\n",
            "|material_id|material_name|workspace_id|workspace_name|\n",
            "+-----------+-------------+------------+--------------+\n",
            "|      83515|      LB20W40|          53|        Nayara|\n",
            "|      83498|       MS Reg|          53|        Nayara|\n",
            "|      83499|      MS Prem|          53|        Nayara|\n",
            "|      83500|      HSD Reg|          53|        Nayara|\n",
            "|      83501|     HSD Prem|          53|        Nayara|\n",
            "|      83502|Lube20w40 XYZ|          53|        Nayara|\n",
            "|      83503|     Gasoline|          53|        Nayara|\n",
            "|      83504|       Diesel|          53|        Nayara|\n",
            "|      83505|    Auto Lube|          53|        Nayara|\n",
            "|      83506|      Regular|          53|        Nayara|\n",
            "|      83507|      Premium|          53|        Nayara|\n",
            "|      83508|          XYZ|          53|        Nayara|\n",
            "|      83509|         Fuel|          53|        Nayara|\n",
            "|      83510|   Lubricants|          53|        Nayara|\n",
            "|      83511|         MS92|          53|        Nayara|\n",
            "|      83512|         MS95|          53|        Nayara|\n",
            "|      83513|         HSDR|          53|        Nayara|\n",
            "|      83514|        HSDRP|          53|        Nayara|\n",
            "|      83516|          All|          53|        Nayara|\n",
            "+-----------+-------------+------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select material_id, material_name, workspace_id,workspace_name from in_material\n",
        "join in_workspace\n",
        "using (workspace_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abbb82e5",
      "metadata": {},
      "source": [
        "**Q25.** Show resource (geography) names along with their workspace names where `workspace_id = 53`. Output columns: `resource_id`, `resource_name`, `workspace_id`, `workspace_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b2eda465",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+------------+--------------+\n",
            "|geography_id|       resource_name|workspace_id|workspace_name|\n",
            "+------------+--------------------+------------+--------------+\n",
            "|       30113|  Elhaam Corporation|          53|        Nayara|\n",
            "|       30114| Yashkalgi Petroleum|          53|        Nayara|\n",
            "|       30115|  Sukhmani Petroleum|          53|        Nayara|\n",
            "|       30116|Vrajpari Corporation|          53|        Nayara|\n",
            "|       30117|Sai Shakti Petroleum|          53|        Nayara|\n",
            "|       30118|           BMF Fuels|          53|        Nayara|\n",
            "|       30119|       R K Petroleum|          53|        Nayara|\n",
            "|       30120|    Aastha Petroleum|          53|        Nayara|\n",
            "|       30121|        JP Petroleum|          53|        Nayara|\n",
            "|       30122|   UmiyaJi Petroleum|          53|        Nayara|\n",
            "|       30123|Nilkanth Petroleu...|          53|        Nayara|\n",
            "|       30124|    Rusabh Petroleum|          53|        Nayara|\n",
            "|       30125|Nilkanth Petroleu...|          53|        Nayara|\n",
            "|       30126|Kalptaru Petro St...|          53|        Nayara|\n",
            "|       30127|    Amba Petrol Pump|          53|        Nayara|\n",
            "|       30128|     Mauli Petroleum|          53|        Nayara|\n",
            "|       30129|Tidke Service Sta...|          53|        Nayara|\n",
            "|       30130|Five Elements Wat...|          53|        Nayara|\n",
            "|       30131|Bhiwandi Automobiles|          53|        Nayara|\n",
            "|       30132|       A P Petroleum|          53|        Nayara|\n",
            "+------------+--------------------+------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select geography_id, resource_name, w.workspace_id,workspace_name from in_resource\n",
        "join in_workspace as w\n",
        "using(workspace_id)\n",
        "where workspace_id= 53\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f08ff7ac",
      "metadata": {},
      "source": [
        "**Q26.** Display time dimension names with their associated workspace names. Output columns: `time_dimension_id`, `time_dimension_name`, `workspace_id`, `workspace_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b0cdb6bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-------------------+------------+--------------+\n",
            "|time_dimension_id|time_dimension_name|workspace_id|workspace_name|\n",
            "+-----------------+-------------------+------------+--------------+\n",
            "|               64|            Quarter|          53|        Nayara|\n",
            "|               65|               Year|          53|        Nayara|\n",
            "|               63|              Month|          53|        Nayara|\n",
            "+-----------------+-------------------+------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select time_level_id as time_dimension_id, time_dimension_name, workspace_id,workspace_name  from in_time_dimension\n",
        "join in_workspace\n",
        "using(workspace_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1af34c6",
      "metadata": {},
      "source": [
        "**Q27.** Show timeseries IDs along with their corresponding material names where `workspace_id = 53`. Output columns: `ts_id`, `material_id`, `material_name`, `workspace_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "93cc4b9b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------+-------------+------------+\n",
            "|ts_id|material_id|material_name|workspace_id|\n",
            "+-----+-----------+-------------+------------+\n",
            "|27803|      83498|       MS Reg|          53|\n",
            "|27804|      83499|      MS Prem|          53|\n",
            "|27805|      83500|      HSD Reg|          53|\n",
            "|27806|      83501|     HSD Prem|          53|\n",
            "|27807|      83502|Lube20w40 XYZ|          53|\n",
            "|27808|      83498|       MS Reg|          53|\n",
            "|27809|      83499|      MS Prem|          53|\n",
            "|27810|      83500|      HSD Reg|          53|\n",
            "|27811|      83501|     HSD Prem|          53|\n",
            "|27812|      83502|Lube20w40 XYZ|          53|\n",
            "|27813|      83498|       MS Reg|          53|\n",
            "|27814|      83499|      MS Prem|          53|\n",
            "|27815|      83500|      HSD Reg|          53|\n",
            "|27816|      83501|     HSD Prem|          53|\n",
            "|27817|      83502|Lube20w40 XYZ|          53|\n",
            "|27818|      83498|       MS Reg|          53|\n",
            "|27819|      83499|      MS Prem|          53|\n",
            "|27820|      83500|      HSD Reg|          53|\n",
            "|27821|      83501|     HSD Prem|          53|\n",
            "|27822|      83502|Lube20w40 XYZ|          53|\n",
            "+-----+-----------+-------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_id, m.material_id, material_name,m.workspace_id from in_timeseries as t\n",
        "join in_material as m\n",
        "using(material_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642ad114",
      "metadata": {},
      "source": [
        "**Q28.** Display timeseries data along with their version names where `workspace_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `version_id`, `version_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a82d5537",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+----------+------------+\n",
            "|ts_data_id|ts_id|             dttime|     data|version_id|version_name|\n",
            "+----------+-----+-------------------+---------+----------+------------+\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|       130| Forecast-MA|\n",
            "|  44471774|27902|2018-12-01 00:00:00| 11513.37|       130| Forecast-MA|\n",
            "|  44471775|27902|2019-01-01 00:00:00|11556.125|       130| Forecast-MA|\n",
            "|  44471776|27902|2019-02-01 00:00:00|11598.547|       130| Forecast-MA|\n",
            "|  44471777|27902|2019-03-01 00:00:00|11643.222|       130| Forecast-MA|\n",
            "|  44471778|27902|2019-04-01 00:00:00| 11687.96|       130| Forecast-MA|\n",
            "|  44471779|27902|2019-05-01 00:00:00|11732.147|       130| Forecast-MA|\n",
            "|  44471780|27902|2019-06-01 00:00:00|11775.567|       130| Forecast-MA|\n",
            "|  44471781|27902|2019-07-01 00:00:00|11820.099|       130| Forecast-MA|\n",
            "|  44471782|27902|2019-08-01 00:00:00|11863.516|       130| Forecast-MA|\n",
            "|  44471783|27902|2019-09-01 00:00:00|11907.183|       130| Forecast-MA|\n",
            "|  44471784|27902|2019-10-01 00:00:00|11949.934|       130| Forecast-MA|\n",
            "|  44471785|27902|2019-11-01 00:00:00|11994.433|       130| Forecast-MA|\n",
            "|  44471786|27902|2019-12-01 00:00:00|12038.495|       130| Forecast-MA|\n",
            "|  44471787|27902|2020-01-01 00:00:00|11890.158|       130| Forecast-MA|\n",
            "|  44471788|27902|2020-02-01 00:00:00|11741.922|       130| Forecast-MA|\n",
            "|  44471789|27902|2020-03-01 00:00:00|11592.161|       130| Forecast-MA|\n",
            "|  44471790|27902|2020-04-01 00:00:00|11442.587|       130| Forecast-MA|\n",
            "|  44471791|27902|2020-05-01 00:00:00|11292.527|       130| Forecast-MA|\n",
            "|  44471792|27902|2020-06-01 00:00:00| 11143.59|       130| Forecast-MA|\n",
            "+----------+-----+-------------------+---------+----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data, version_id,version_name from in_timeseries_data\n",
        "join in_timeseries_version\n",
        "using(version_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e0642f",
      "metadata": {},
      "source": [
        "**Q29.** Show all users and their account names where `account_id > 1`. Output columns: `id`, `username`, `account_id`, `name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "f72dd52d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----------+----------+-------------------+\n",
            "| id|   username|account_id|               name|\n",
            "+---+-----------+----------+-------------------+\n",
            "|  1|      admin|         1|       ESPL_Account|\n",
            "|  3|hetal.patel|         1|              Enpro|\n",
            "|  4|       ravi|         1|         Indian Oil|\n",
            "|  5| customer_1|         1|Standard Automotive|\n",
            "|  7|   pratik.m|         3|           ESPL_UAT|\n",
            "+---+-----------+----------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select  id, username, account_id,name from ab_user \n",
        "join sy_account\n",
        "using(id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb8ecbe",
      "metadata": {},
      "source": [
        "**Q30.** Display application module names along with their application descriptions. Output columns: `app_id`, `app_name`, `application_id`, `application_name`, `application_description`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "dacd5f38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+--------------+----------------+-----------------------+\n",
            "|app_id|            app_name|application_id|application_name|application_description|\n",
            "+------+--------------------+--------------+----------------+-----------------------+\n",
            "|    19| XBridge-Integration|             5|         XBridge|   XBridge: Data Eng...|\n",
            "|    14|Radar-Demand Plan...|             3|          XSight|   XSoght: Predictiv...|\n",
            "|     6|        Trinity-S&OP|             2|           XPlan|   XPlan: Prescripti...|\n",
            "+------+--------------------+--------------+----------------+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select app_id, app_name, application_id, application_name,application_description from sy_app_module\n",
        "join sy_application\n",
        "using (application_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87cfac5",
      "metadata": {},
      "source": [
        "**Q31.** Show model names and their descriptions along with the application module name. Output columns: `model_id`, `model_name`, `model_description`, `app_id`, `app_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "51758046",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----------+------------------+------+--------------------+\n",
            "|model_id| model_name| model_description|app_id|            app_name|\n",
            "+--------+-----------+------------------+------+--------------------+\n",
            "|      29|Oil and Gas|Oil and Gas Sector|    14|Radar-Demand Plan...|\n",
            "+--------+-----------+------------------+------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select model_id, model_name, model_description,m.app_id,app_name from in_model as m\n",
        "join sy_app_module\n",
        "using (application_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388c1816",
      "metadata": {},
      "source": [
        "**Q32.** Show workspace name, model name, and application name for `workspace_id = 53`. Output columns: `workspace_id`, `workspace_name`, `model_id`, `model_name`, `application_id`, `application_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "68114d34",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------+--------+-----------+--------------+----------------+\n",
            "|workspace_id|workspace_name|model_id| model_name|application_id|application_name|\n",
            "+------------+--------------+--------+-----------+--------------+----------------+\n",
            "|          53|        Nayara|      29|Oil and Gas|             3|          XSight|\n",
            "+------------+--------------+--------+-----------+--------------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select workspace_id, workspace_name, model_id, model_name, application_id,application_name from in_workspace\n",
        "join in_model\n",
        "using (model_id)\n",
        "join sy_application\n",
        "using (application_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac8824d",
      "metadata": {},
      "source": [
        "**Q33.** Display timeseries ID, material name, geography name, and time dimension name for `workspace_id = 53`. Output columns: `ts_id`, `material_id`, `material_name`, `resource_id`, `resource_name`, `time_dimension_id`, `time_dimension_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "d4e8faa4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------+-------------+-----------+------------------+-------------+-------------------+\n",
            "|ts_id|material_id|material_name|resource_id|    geography_name|time_level_id|time_dimension_name|\n",
            "+-----+-----------+-------------+-----------+------------------+-------------+-------------------+\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           64|            Quarter|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           64|            Quarter|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           64|            Quarter|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           64|            Quarter|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           64|            Quarter|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           64|            Quarter|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           63|              Month|\n",
            "|27904|      83508|          XYZ|      30113|Elhaam Corporation|           65|               Year|\n",
            "+-----+-----------+-------------+-----------+------------------+-------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select  td.ts_id, m.material_id, material_name, r.geography_id as resource_id, resource_name as geography_name ,td.time_level_id,time_dimension_name from in_material as m\n",
        "join in_resource as r\n",
        "using(workspace_id)\n",
        "join in_timeseries\n",
        "using(material_id)\n",
        "join in_timeseries_data as td\n",
        "using (ts_id)\n",
        "join in_time_dimension as td\n",
        "using(workspace_id)\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4b05415",
      "metadata": {},
      "source": [
        "**Q34.** Display timeseries data value, material name, geography name, and version name where `workspace_id = 53` and `version_id = 125`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `material_id`, `material_name`, `resource_id`, `resource_name`, `version_id`, `version_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "75e7f177",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+-----------+-------------+-----------+--------------+----------+------------+\n",
            "|ts_data_id|ts_id|             dttime|     data|material_id|material_name|resource_id| resource_name|version_id|version_name|\n",
            "+----------+-----+-------------------+---------+-----------+-------------+-----------+--------------+----------+------------+\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30241|       Bhiwadi|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30240|          Kota|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30239|       Jodhpur|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30238|        Jaipur|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30237|         Akola|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30236|        Wardha|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30235|    Ahmednagar|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30234|      Kolhapur|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30233|      Amravati|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30232|       Jalgaon|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30231|       Solapur|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30230|    Aurangabad|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30229|         Thane|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30228|        Nagpur|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30227|        Nashik|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30301|         Delhi|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30300|Madhya Pradesh|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30299|     Rajasthan|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30298|   Maharashtra|       125|         Raw|\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|      83515|      LB20W40|      30297|       Gujarat|       125|         Raw|\n",
            "+----------+-----+-------------------+---------+-----------+-------------+-----------+--------------+----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select  ts_data_id, ts_id, dttime, data, material_id, material_name,geography_id as resource_id, resource_name, version_id,version_name \n",
        "          from in_timeseries_data\n",
        "          join in_timeseries_version\n",
        "          using (version_id)\n",
        "          cross join in_material as m\n",
        "          join in_resource\n",
        "          using (workspace_id)\n",
        "          where m.workspace_id=53 and version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a45cf9",
      "metadata": {},
      "source": [
        "**Q35.** Show the latest 10 timeseries records (by datetime descending) for `workspace_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `material_name`, `resource_name`, `time_dimension_name`, `version_name`, `workspace_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "96e94022",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+-------------+--------------+-------------------+------------+--------------+\n",
            "|ts_data_id|ts_id|             dttime|     data|material_name|geography_name|time_dimension_name|version_name|workspace_name|\n",
            "+----------+-----+-------------------+---------+-------------+--------------+-------------------+------------+--------------+\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|       Bhiwadi|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|       Bhiwadi|               Year| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|       Bhiwadi|            Quarter| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|          Kota|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|          Kota|               Year| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|          Kota|            Quarter| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|       Jodhpur|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|       Jodhpur|               Year| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|       Jodhpur|            Quarter| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|        Jaipur|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|        Jaipur|               Year| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|        Jaipur|            Quarter| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|         Akola|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|         Akola|               Year| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|         Akola|            Quarter| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|        Wardha|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|        Wardha|               Year| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|        Wardha|            Quarter| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|    Ahmednagar|              Month| Forecast-MA|        Nayara|\n",
            "|  44471796|27902|2020-10-01 00:00:00|10549.207|      LB20W40|    Ahmednagar|               Year| Forecast-MA|        Nayara|\n",
            "+----------+-----+-------------------+---------+-------------+--------------+-------------------+------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data, material_name, resource_name as geography_name, time_dimension_name, version_name,workspace_name\n",
        "          from in_timeseries_data\n",
        "        cross join in_material\n",
        "        join in_resource\n",
        "        using(workspace_id)\n",
        "        join in_time_dimension\n",
        "        using(workspace_id)\n",
        "        join in_workspace\n",
        "        using(workspace_id)\n",
        "        join in_timeseries_version\n",
        "        using(version_id) \n",
        "        where workspace_id=53\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da2ae15",
      "metadata": {},
      "source": [
        "**Q36.** Assign a row number to each timeseries data record within `version_id =125`, ordered by `dttime`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `version_id`, `row_num`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "7a64bd4d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+----------+----------+-------+\n",
            "|ts_data_id|ts_id|             dttime|      data|version_id|row_num|\n",
            "+----------+-----+-------------------+----------+----------+-------+\n",
            "|  43179600|27398|2018-01-01 00:00:00|  71.55379|       125|      1|\n",
            "|  43180659|27419|2018-01-01 00:00:00|   36.3825|       125|      2|\n",
            "|  43179704|27400|2018-01-01 00:00:00|  99.41498|       125|      3|\n",
            "|  43178157|27371|2018-01-01 00:00:00|  2901.168|       125|      4|\n",
            "|  43179756|27401|2018-01-01 00:00:00| 11.840634|       125|      5|\n",
            "|  43178002|27368|2018-01-01 00:00:00| 18240.324|       125|      6|\n",
            "|  43179807|27402|2018-01-01 00:00:00| 1.4639626|       125|      7|\n",
            "|  43178320|27374|2018-01-01 00:00:00| 2324.7139|       125|      8|\n",
            "|  43179867|27403|2018-01-01 00:00:00|10414.8545|       125|      9|\n",
            "|  43178535|27378|2018-01-01 00:00:00| 25692.166|       125|     10|\n",
            "|  43179918|27404|2018-01-01 00:00:00| 1280.0442|       125|     11|\n",
            "|  43178690|27381|2018-01-01 00:00:00|  4009.496|       125|     12|\n",
            "|  43179970|27405|2018-01-01 00:00:00| 14683.716|       125|     13|\n",
            "|  43178853|27384|2018-01-01 00:00:00| 111.46248|       125|     14|\n",
            "|  43180022|27406|2018-01-01 00:00:00| 1710.1425|       125|     15|\n",
            "|  43179119|27389|2018-01-01 00:00:00| 1034.3132|       125|     16|\n",
            "|  43180074|27407|2018-01-01 00:00:00| 215.73337|       125|     17|\n",
            "|  43179275|27392|2018-01-01 00:00:00| 166.35504|       125|     18|\n",
            "|  43180127|27408|2018-01-01 00:00:00|  9270.441|       125|     19|\n",
            "|  43179541|27397|2018-01-01 00:00:00| 177.35306|       125|     20|\n",
            "+----------+-----+-------------------+----------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data, version_id,\n",
        "\t\trow_number() over(order by dttime asc)as row_num from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74417b6f",
      "metadata": {},
      "source": [
        "**Q37.** Rank timeseries data values within each `version_id=125` ordered by `data` value descending. Output columns: `ts_data_id`, `ts_id`, `data`, `version_id`, `rank`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "e0cb3df9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+--------+----------+---+\n",
            "|ts_data_id|ts_id|    data|version_id| rk|\n",
            "+----------+-----+--------+----------+---+\n",
            "|  43194636|27688|9999.566|       125|  1|\n",
            "|  43198580|27763|9998.707|       125|  2|\n",
            "|  43194157|27678|9997.176|       125|  3|\n",
            "|  43193960|27675|9996.405|       125|  4|\n",
            "|  43182558|27455|9994.589|       125|  5|\n",
            "|  43187743|27555|999.3399|       125|  6|\n",
            "|  43192580|27648|9987.178|       125|  7|\n",
            "|  43192446|27645|9986.819|       125|  8|\n",
            "|  43202025|27830| 9986.42|       125|  9|\n",
            "|  43194923|27693|9985.631|       125| 10|\n",
            "|  43198816|27768|9983.248|       125| 11|\n",
            "|  43189566|27590|9982.525|       125| 12|\n",
            "|  43181745|27440|9981.848|       125| 13|\n",
            "|  43196601|27725|9980.734|       125| 14|\n",
            "|  43191404|27625|9978.993|       125| 15|\n",
            "|  43197542|27743|9978.085|       125| 16|\n",
            "|  43192576|27648| 9977.19|       125| 17|\n",
            "|  43194008|27675|9976.452|       125| 18|\n",
            "|  43187477|27550|9974.119|       125| 19|\n",
            "|  43185948|27520|9973.939|       125| 20|\n",
            "+----------+-----+--------+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, data, version_id,\n",
        "\t\trank() over(order by data desc) as rk from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04630bca",
      "metadata": {},
      "source": [
        "**Q38.** Calculate the running total (cumulative sum) of `data` values for each `ts_id`, ordered by `dttime`, for `workspace_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `version_id`, `running_total`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "17b134f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+----------+---------------+\n",
            "|ts_data_id|ts_id|             dttime|     data|version_id|  running_total|\n",
            "+----------+-----+-------------------+---------+----------+---------------+\n",
            "|  43177787|27363|2018-01-01 00:00:00|2915.9478|       125|2818629.7203409|\n",
            "|  43177995|27367|2018-01-01 00:00:00|58.944374|       125|2818629.7203409|\n",
            "|  43178002|27368|2018-01-01 00:00:00|18240.324|       125|2818629.7203409|\n",
            "|  43178157|27371|2018-01-01 00:00:00| 2901.168|       125|2818629.7203409|\n",
            "|  43178268|27373|2018-01-01 00:00:00|19071.441|       125|2818629.7203409|\n",
            "|  43178320|27374|2018-01-01 00:00:00|2324.7139|       125|2818629.7203409|\n",
            "|  43178424|27376|2018-01-01 00:00:00|3224.8557|       125|2818629.7203409|\n",
            "|  43178535|27378|2018-01-01 00:00:00|25692.166|       125|2818629.7203409|\n",
            "|  43178586|27379|2018-01-01 00:00:00|3095.1455|       125|2818629.7203409|\n",
            "|  43178690|27381|2018-01-01 00:00:00| 4009.496|       125|2818629.7203409|\n",
            "|  43178742|27382|2018-01-01 00:00:00|  501.187|       125|2818629.7203409|\n",
            "|  43178853|27384|2018-01-01 00:00:00|111.46248|       125|2818629.7203409|\n",
            "|  43179008|27387|2018-01-01 00:00:00|    17.64|       125|2818629.7203409|\n",
            "|  43179119|27389|2018-01-01 00:00:00|1034.3132|       125|2818629.7203409|\n",
            "|  43179171|27390|2018-01-01 00:00:00|10889.678|       125|2818629.7203409|\n",
            "|  43179275|27392|2018-01-01 00:00:00|166.35504|       125|2818629.7203409|\n",
            "|  43179437|27395|2018-01-01 00:00:00|11692.965|       125|2818629.7203409|\n",
            "|  43179541|27397|2018-01-01 00:00:00|177.35306|       125|2818629.7203409|\n",
            "|  43179600|27398|2018-01-01 00:00:00| 71.55379|       125|2818629.7203409|\n",
            "|  43179704|27400|2018-01-01 00:00:00| 99.41498|       125|2818629.7203409|\n",
            "+----------+-----+-------------------+---------+----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data, version_id,\n",
        "\t\tsum(data) over(order by dttime) as running_total from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d24cb3",
      "metadata": {},
      "source": [
        "**Q39.** Find the previous and next `data` values for each timeseries record ordered by `dttime`, where `workspace_id = 53` and `version_id = 125`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `previous_value`, `next_value`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "c86ae196",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+--------------+----------+\n",
            "|ts_data_id|ts_id|             dttime|     data|previous_value|next_value|\n",
            "+----------+-----+-------------------+---------+--------------+----------+\n",
            "|  43177787|27363|2018-01-01 00:00:00|2915.9478|          NULL| 58.944374|\n",
            "|  43177995|27367|2018-01-01 00:00:00|58.944374|     2915.9478| 18240.324|\n",
            "|  43178002|27368|2018-01-01 00:00:00|18240.324|     58.944374|  2901.168|\n",
            "|  43178157|27371|2018-01-01 00:00:00| 2901.168|     18240.324| 19071.441|\n",
            "|  43178268|27373|2018-01-01 00:00:00|19071.441|      2901.168| 2324.7139|\n",
            "|  43178320|27374|2018-01-01 00:00:00|2324.7139|     19071.441| 3224.8557|\n",
            "|  43178424|27376|2018-01-01 00:00:00|3224.8557|     2324.7139| 25692.166|\n",
            "|  43178535|27378|2018-01-01 00:00:00|25692.166|     3224.8557| 3095.1455|\n",
            "|  43178586|27379|2018-01-01 00:00:00|3095.1455|     25692.166|  4009.496|\n",
            "|  43178690|27381|2018-01-01 00:00:00| 4009.496|     3095.1455|   501.187|\n",
            "|  43178742|27382|2018-01-01 00:00:00|  501.187|      4009.496| 111.46248|\n",
            "|  43178853|27384|2018-01-01 00:00:00|111.46248|       501.187|     17.64|\n",
            "|  43179008|27387|2018-01-01 00:00:00|    17.64|     111.46248| 1034.3132|\n",
            "|  43179119|27389|2018-01-01 00:00:00|1034.3132|         17.64| 10889.678|\n",
            "|  43179171|27390|2018-01-01 00:00:00|10889.678|     1034.3132| 166.35504|\n",
            "|  43179275|27392|2018-01-01 00:00:00|166.35504|     10889.678| 11692.965|\n",
            "|  43179437|27395|2018-01-01 00:00:00|11692.965|     166.35504| 177.35306|\n",
            "|  43179541|27397|2018-01-01 00:00:00|177.35306|     11692.965|  71.55379|\n",
            "|  43179600|27398|2018-01-01 00:00:00| 71.55379|     177.35306|  99.41498|\n",
            "|  43179704|27400|2018-01-01 00:00:00| 99.41498|      71.55379| 11.840634|\n",
            "+----------+-----+-------------------+---------+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data, \n",
        "\t\tlag(data) over(order by dttime) as previous_value,\n",
        "        lead(data)over(order by dttime) as next_value from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff02c65",
      "metadata": {},
      "source": [
        "**Q40.** Calculate the moving average of `data` values over the last 3 records (including current) for each timeseries ordered by `dttime`, where `workspace_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `moving_avg_3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "dedb3350",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+------------------+\n",
            "|ts_data_id|ts_id|             dttime|     data|      moving_avg_3|\n",
            "+----------+-----+-------------------+---------+------------------+\n",
            "|  43177787|27363|2018-01-01 00:00:00|2915.9478|         2915.9478|\n",
            "|  43177995|27367|2018-01-01 00:00:00|58.944374|       1487.446087|\n",
            "|  43178002|27368|2018-01-01 00:00:00|18240.324| 7071.738724666667|\n",
            "|  43178157|27371|2018-01-01 00:00:00| 2901.168| 7066.812124666667|\n",
            "|  43178268|27373|2018-01-01 00:00:00|19071.441|13404.311000000002|\n",
            "|  43178320|27374|2018-01-01 00:00:00|2324.7139| 8099.107633333333|\n",
            "|  43178424|27376|2018-01-01 00:00:00|3224.8557| 8207.003533333333|\n",
            "|  43178535|27378|2018-01-01 00:00:00|25692.166|10413.911866666667|\n",
            "|  43178586|27379|2018-01-01 00:00:00|3095.1455|        10670.7224|\n",
            "|  43178690|27381|2018-01-01 00:00:00| 4009.496|10932.269166666667|\n",
            "|  43178742|27382|2018-01-01 00:00:00|  501.187|2535.2761666666665|\n",
            "|  43178853|27384|2018-01-01 00:00:00|111.46248|        1540.71516|\n",
            "|  43179008|27387|2018-01-01 00:00:00|    17.64|210.09649333333334|\n",
            "|  43179119|27389|2018-01-01 00:00:00|1034.3132|387.80522666666667|\n",
            "|  43179171|27390|2018-01-01 00:00:00|10889.678|3980.5437333333334|\n",
            "|  43179275|27392|2018-01-01 00:00:00|166.35504|4030.1154133333334|\n",
            "|  43179437|27395|2018-01-01 00:00:00|11692.965|7582.9993466666665|\n",
            "|  43179541|27397|2018-01-01 00:00:00|177.35306| 4012.224366666667|\n",
            "|  43179600|27398|2018-01-01 00:00:00| 71.55379|3980.6239499999997|\n",
            "|  43179704|27400|2018-01-01 00:00:00| 99.41498|116.10727666666668|\n",
            "+----------+-----+-------------------+---------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data,\n",
        "\t\tavg(data) over (order by dttime rows between 2 preceding and current row) as moving_avg_3 from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabc76e5",
      "metadata": {},
      "source": [
        "**Q41.** Assign a dense rank to materials based on the count of their timeseries records in `workspace_id = 53`. Output columns: `material_id`, `timeseries_count`, `dense_rank`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "13b2405f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+----------------+----------+\n",
            "|material_id|timeseries_count|dense_rank|\n",
            "+-----------+----------------+----------+\n",
            "|      83498|              19|         1|\n",
            "|      83499|              19|         2|\n",
            "|      83500|              19|         3|\n",
            "|      83501|              19|         4|\n",
            "|      83502|              19|         5|\n",
            "|      83503|              19|         6|\n",
            "|      83504|              19|         7|\n",
            "|      83505|              19|         8|\n",
            "|      83506|              19|         9|\n",
            "|      83507|              19|        10|\n",
            "|      83508|              19|        11|\n",
            "|      83509|              19|        12|\n",
            "|      83510|              19|        13|\n",
            "|      83511|              19|        14|\n",
            "|      83512|              19|        15|\n",
            "|      83513|              19|        16|\n",
            "|      83514|              19|        17|\n",
            "|      83515|              19|        18|\n",
            "|      83516|              19|        19|\n",
            "+-----------+----------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select material_id,\n",
        "\t\tcount(*) over(partition by workspace_id) as  timeseries_count,\n",
        "\t\tdense_rank() over(order by material_id) as dense_rank from in_material\n",
        "where workspace_id=53\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22f31650",
      "metadata": {},
      "source": [
        "**Q42.** Partition timeseries data by `version_id` and display the maximum `data` value within each version for `version_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `version_id`, `max_in_version`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "87b5278f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+----------+--------------+\n",
            "|ts_data_id|ts_id|             dttime|     data|version_id|max_in_version|\n",
            "+----------+-----+-------------------+---------+----------+--------------+\n",
            "|  43177824|27364|2019-04-01 00:00:00|381.43152|       125|      9999.566|\n",
            "|  43177754|27363|2020-10-01 00:00:00|2041.8203|       125|      9999.566|\n",
            "|  43177755|27363|2020-09-01 00:00:00| 1921.837|       125|      9999.566|\n",
            "|  43177756|27363|2020-08-01 00:00:00|1991.6937|       125|      9999.566|\n",
            "|  43177757|27363|2020-07-01 00:00:00|1933.8904|       125|      9999.566|\n",
            "|  43177758|27363|2020-06-01 00:00:00|1984.3469|       125|      9999.566|\n",
            "|  43177759|27363|2020-05-01 00:00:00|1891.3866|       125|      9999.566|\n",
            "|  43177760|27363|2020-04-01 00:00:00|1829.2837|       125|      9999.566|\n",
            "|  43177761|27363|2020-03-01 00:00:00|2682.4043|       125|      9999.566|\n",
            "|  43177762|27363|2020-02-01 00:00:00| 2533.259|       125|      9999.566|\n",
            "|  43177763|27363|2020-01-01 00:00:00|2597.7861|       125|      9999.566|\n",
            "|  43177764|27363|2019-12-01 00:00:00|2419.9697|       125|      9999.566|\n",
            "|  43177765|27363|2019-11-01 00:00:00|2399.9453|       125|      9999.566|\n",
            "|  43177766|27363|2019-10-01 00:00:00|2397.4182|       125|      9999.566|\n",
            "|  43177767|27363|2019-09-01 00:00:00| 2254.287|       125|      9999.566|\n",
            "|  43177768|27363|2019-08-01 00:00:00| 2340.898|       125|      9999.566|\n",
            "|  43177769|27363|2019-07-01 00:00:00|2268.4253|       125|      9999.566|\n",
            "|  43177770|27363|2019-06-01 00:00:00|2327.6055|       125|      9999.566|\n",
            "|  43177771|27363|2019-05-01 00:00:00|2218.5625|       125|      9999.566|\n",
            "|  43177772|27363|2019-04-01 00:00:00| 2147.867|       125|      9999.566|\n",
            "+----------+-----+-------------------+---------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, dttime, data, version_id,\n",
        "\t\tmax(data) over(partition by version_id) as max_in_version from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a70a78bd",
      "metadata": {},
      "source": [
        "**Q43.** Calculate the percentage contribution of each `data` value to the total sum of its version for `version_id = 53`. Output columns: `ts_data_id`, `ts_id`, `data`, `version_id`, `percentage_of_total`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "ac7ee5d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+---------+----------+--------------------+\n",
            "|ts_data_id|ts_id|     data|version_id| percentage_of_total|\n",
            "+----------+-----+---------+----------+--------------------+\n",
            "|  43177824|27364|381.43152|       125|3.208994639528634E-4|\n",
            "|  43177754|27363|2041.8203|       125|0.001717789446866045|\n",
            "|  43177755|27363| 1921.837|       125|0.001616847142325...|\n",
            "|  43177756|27363|1991.6937|       125|0.001675617790287...|\n",
            "|  43177757|27363|1933.8904|       125|0.001626987703332...|\n",
            "|  43177758|27363|1984.3469|       125|0.001669436905755...|\n",
            "|  43177759|27363|1891.3866|       125|0.001591229130900...|\n",
            "|  43177760|27363|1829.2837|       125|0.001538981777771566|\n",
            "|  43177761|27363|2682.4043|       125| 0.00225671465739081|\n",
            "|  43177762|27363| 2533.259|       125|0.002131238276149...|\n",
            "|  43177763|27363|2597.7861|       125|0.002185525115895508|\n",
            "|  43177764|27363|2419.9697|       125|0.002035927653572447|\n",
            "|  43177765|27363|2399.9453|       125|0.002019081066730...|\n",
            "|  43177766|27363|2397.4182|       125|0.002016955010039...|\n",
            "|  43177767|27363| 2254.287|       125|0.001896538308884144|\n",
            "|  43177768|27363| 2340.898|       125| 0.00196940439890319|\n",
            "|  43177769|27363|2268.4253|       125|0.001908432902417486|\n",
            "|  43177770|27363|2327.6055|       125|0.001958221379407...|\n",
            "|  43177771|27363|2218.5625|       125|0.001866483181557...|\n",
            "|  43177772|27363| 2147.867|       125|0.001807006848679...|\n",
            "+----------+-----+---------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id, ts_id, data, version_id, \n",
        "\t\t (data / SUM(data) OVER ()) * 100 AS percentage_of_total from in_timeseries_data\n",
        "where version_id=125\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461ad897",
      "metadata": {},
      "source": [
        "**Q44.** Find the first and last `data` values for each `ts_id` ordered by `dttime`, where `workspace_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `first_value`, `last_value`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "c3ee82c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+-----------+----------+\n",
            "|ts_data_id|ts_id|             dttime|     data|first_value|last_value|\n",
            "+----------+-----+-------------------+---------+-----------+----------+\n",
            "|  43177787|27363|2018-01-01 00:00:00|2915.9478|  2915.9478|  2055.375|\n",
            "|  43177786|27363|2018-02-01 00:00:00|2846.3586|  2915.9478|  2055.375|\n",
            "|  43177785|27363|2018-03-01 00:00:00|3013.9375|  2915.9478|  2055.375|\n",
            "|  43177784|27363|2018-04-01 00:00:00|2057.4304|  2915.9478|  2055.375|\n",
            "|  43177783|27363|2018-05-01 00:00:00| 2129.408|  2915.9478|  2055.375|\n",
            "|  43177782|27363|2018-06-01 00:00:00| 2225.144|  2915.9478|  2055.375|\n",
            "|  43177781|27363|2018-07-01 00:00:00|2172.9106|  2915.9478|  2055.375|\n",
            "|  43177780|27363|2018-08-01 00:00:00|2237.8582|  2915.9478|  2055.375|\n",
            "|  43177779|27363|2018-09-01 00:00:00|2159.3674|  2915.9478|  2055.375|\n",
            "|  43177778|27363|2018-10-01 00:00:00|2294.1802|  2915.9478|  2055.375|\n",
            "|  43177777|27363|2018-11-01 00:00:00|2296.5984|  2915.9478|  2055.375|\n",
            "|  43177776|27363|2018-12-01 00:00:00|2308.8203|  2915.9478|  2055.375|\n",
            "|  43177775|27363|2019-01-01 00:00:00| 3038.033|  2915.9478|  2055.375|\n",
            "|  43177774|27363|2019-02-01 00:00:00|2980.3997|  2915.9478|  2055.375|\n",
            "|  43177773|27363|2019-03-01 00:00:00|3146.4119|  2915.9478|  2055.375|\n",
            "|  43177772|27363|2019-04-01 00:00:00| 2147.867|  2915.9478|  2055.375|\n",
            "|  43177771|27363|2019-05-01 00:00:00|2218.5625|  2915.9478|  2055.375|\n",
            "|  43177770|27363|2019-06-01 00:00:00|2327.6055|  2915.9478|  2055.375|\n",
            "|  43177769|27363|2019-07-01 00:00:00|2268.4253|  2915.9478|  2055.375|\n",
            "|  43177768|27363|2019-08-01 00:00:00| 2340.898|  2915.9478|  2055.375|\n",
            "+----------+-----+-------------------+---------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          SELECT ts_data_id,ts_id,dttime, data,\n",
        "    FIRST_VALUE(data) OVER (PARTITION BY ts_id ORDER BY dttime ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS first_value,\n",
        "    LAST_VALUE(data) OVER ( PARTITION BY ts_id ORDER BY dttime ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_value\n",
        "FROM in_timeseries_data\n",
        "WHERE version_id = 125\n",
        "ORDER BY ts_id, dttime\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0454b2a5",
      "metadata": {},
      "source": [
        "**Q45.** Calculate the difference between each `data` value and the average `data` value within its version for `version_id =125`. Output columns: `ts_data_id`, `ts_id`, `data`, `version_id`, `avg_in_version`, `difference_from_avg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "8fde1bad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+---------+----------+------------------+-------------------+\n",
            "|ts_data_id|ts_id|     data|version_id|    avg_in_version|difference_from_avg|\n",
            "+----------+-----+---------+----------+------------------+-------------------+\n",
            "|  43177736|27363| 2055.375|       125|4571.6633166697975|-2516.2883166697975|\n",
            "|  43177737|27363|3022.9883|       125|4571.6633166697975|-1548.6750166697975|\n",
            "|  43177738|27363|2854.9062|       125|4571.6633166697975|-1716.7571166697976|\n",
            "|  43177739|27363|2915.9478|       125|4571.6633166697975|-1655.7155166697976|\n",
            "|  43177740|27363| 2147.203|       125|4571.6633166697975|-2424.4603166697975|\n",
            "|  43177741|27363|2137.9722|       125|4571.6633166697975|-2433.6911166697973|\n",
            "|  43177742|27363| 2142.139|       125|4571.6633166697975|-2429.5243166697974|\n",
            "|  43177743|27363|2002.1992|       125|4571.6633166697975|-2569.4641166697975|\n",
            "|  43177744|27363| 2081.208|       125|4571.6633166697975|-2490.4553166697974|\n",
            "|  43177745|27363|2014.7565|       125|4571.6633166697975|-2556.9068166697975|\n",
            "|  43177746|27363|2071.4575|       125|4571.6633166697975|-2500.2058166697975|\n",
            "|  43177747|27363|1982.3279|       125|4571.6633166697975|-2589.3354166697973|\n",
            "|  43177748|27363|1915.3218|       125|4571.6633166697975| -2656.341516669798|\n",
            "|  43177749|27363|2805.7676|       125|4571.6633166697975|-1765.8957166697974|\n",
            "|  43177750|27363|2649.7632|       125|4571.6633166697975|-1921.9001166697976|\n",
            "|  43177751|27363|2714.5405|       125|4571.6633166697975|-1857.1228166697974|\n",
            "|  43177752|27363|2054.8499|       125|4571.6633166697975|-2516.8134166697973|\n",
            "|  43177753|27363|2039.8845|       125|4571.6633166697975|-2531.7788166697974|\n",
            "|  43177754|27363|2041.8203|       125|4571.6633166697975| -2529.843016669797|\n",
            "|  43177755|27363| 1921.837|       125|4571.6633166697975|-2649.8263166697975|\n",
            "+----------+-----+---------+----------+------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id,ts_id,data,version_id,\n",
        "    avg(data) over (partition by version_id) as avg_in_version,\n",
        "    data - avg(data) over (partition by version_id) as difference_from_avg\n",
        "from in_timeseries_data\n",
        "where version_id =125\n",
        "order by version_id, ts_data_id\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec9ca2cb",
      "metadata": {},
      "source": [
        "**Q46.** Rank materials by their total `data` sum across all timeseries in `workspace_id = 53`. Output columns: `material_id`, `material_name`, `total_data_sum`, `rank`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "02587071",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+-------------------+---+\n",
            "|material_id|material_name|     total_data_sum| rk|\n",
            "+-----------+-------------+-------------------+---+\n",
            "|      83500|      HSD Reg|5.789560762242195E7|  1|\n",
            "|      83498|       MS Reg|4.464722608354395E7|  2|\n",
            "|      83501|     HSD Prem|  8706304.853283972|  3|\n",
            "|      83499|      MS Prem|  6524663.734419964|  4|\n",
            "|      83506|      Regular| 3441099.7019999996|  5|\n",
            "|      83502|Lube20w40 XYZ| 1089443.9397443978|  6|\n",
            "|      83507|      Premium|  516862.8430999999|  7|\n",
            "|      83508|          XYZ|  36690.38820000001|  8|\n",
            "+-----------+-------------+-------------------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select m.material_id,m.material_name,\n",
        "\tsum(td.data) as total_data_sum,\n",
        "    rank() over (order by sum(td.data) desc) as rk\n",
        "from in_timeseries_data td\n",
        "join in_timeseries ts\n",
        "using(ts_id)\n",
        "join in_material m\n",
        "using (material_id)\n",
        "where m.workspace_id = 53\n",
        "group by m.material_id, m.material_name\n",
        "order by total_data_sum desc\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93c6258b",
      "metadata": {},
      "source": [
        "**Q47.** Display all timeseries data records where the `data` value is greater than the average `data` value across all records in `workspace_id = 53`. Output columns: `ts_data_id`, `ts_id`, `dttime`, `data`, `version_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "ff3bbe11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-------------------+---------+----------+\n",
            "|ts_data_id|ts_id|             dttime|     data|version_id|\n",
            "+----------+-----+-------------------+---------+----------+\n",
            "|  43182458|27453|2018-01-01 00:00:00|10262.908|       125|\n",
            "|  43178638|27380|2018-01-01 00:00:00|32807.934|       125|\n",
            "|  43182561|27455|2018-01-01 00:00:00|13773.989|       125|\n",
            "|  43178268|27373|2018-01-01 00:00:00|19071.441|       125|\n",
            "|  43182721|27458|2018-01-01 00:00:00|5465.4854|       125|\n",
            "|  43178535|27378|2018-01-01 00:00:00|25692.166|       125|\n",
            "|  43182825|27460|2018-01-01 00:00:00|6968.7466|       125|\n",
            "|  43180341|27413|2018-01-01 00:00:00| 6220.953|       125|\n",
            "|  43182984|27463|2018-01-01 00:00:00|15175.523|       125|\n",
            "|  43179970|27405|2018-01-01 00:00:00|14683.716|       125|\n",
            "|  43183088|27465|2018-01-01 00:00:00|20753.828|       125|\n",
            "|  43180231|27410|2018-01-01 00:00:00|12063.957|       125|\n",
            "|  43183247|27468|2018-01-01 00:00:00| 22413.83|       125|\n",
            "|  43180874|27423|2018-01-01 00:00:00| 6239.635|       125|\n",
            "|  43183351|27470|2018-01-01 00:00:00|30477.016|       125|\n",
            "|  43181140|27428|2018-01-01 00:00:00| 26795.14|       125|\n",
            "|  43183456|27473|2018-01-01 00:00:00|18345.234|       125|\n",
            "|  43181509|27435|2018-01-01 00:00:00|5806.7554|       125|\n",
            "|  43183560|27475|2018-01-01 00:00:00|25299.107|       125|\n",
            "|  43181772|27440|2018-01-01 00:00:00|15472.104|       125|\n",
            "+----------+-----+-------------------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select ts_data_id,ts_id,dttime,data,version_id\n",
        "from (select ts_data_id,ts_id,dttime,data,version_id,\n",
        "\tavg(data) over () as avg_data_all from in_timeseries_data\n",
        "    where version_id =125) as t\n",
        "where data > avg_data_all\n",
        "order by dttime\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c23dbebe",
      "metadata": {},
      "source": [
        "**Q48.** Find the material with the maximum number of timeseries records in `workspace_id = 53`. Output columns: `material_id`, `material_name`, `timeseries_count`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "b9136db2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------+----------------+\n",
            "|material_id|material_name|timeseries_count|\n",
            "+-----------+-------------+----------------+\n",
            "|      83503|     Gasoline|             100|\n",
            "+-----------+-------------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\" \n",
        "          select m.material_id,m.material_name,\n",
        "    count(ts.ts_id) as timeseries_count\n",
        "from in_timeseries ts\n",
        "join in_material m\n",
        "using (material_id)\n",
        "where m.workspace_id = 53\n",
        "group by m.material_id, m.material_name\n",
        "order by timeseries_count desc\n",
        "limit 1\n",
        "          \"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c617126",
      "metadata": {},
      "source": [
        "# -------------------------------------------------------------------------"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
